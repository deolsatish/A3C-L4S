{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "from gym import wrappers\n",
    "from gym import spaces\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kernel_to_csv(filename=\"router1.txt\"):     \n",
    "        \n",
    "\n",
    "    open('newfile.txt','w').writelines([ line for line in open('router1.txt') if 'fq_calculate_drop_prob-start' in line])\n",
    "    csvfile = open('myfile.txt', 'w')\n",
    "\n",
    "    file1 = open('newfile.txt', 'r')\n",
    "    Lines = file1.readlines()\n",
    "    \n",
    "    count = 0\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        count += 1\n",
    "        temp=line.split(\"-\")\n",
    "        temp1=temp[1]\n",
    "        \n",
    "        temp1=temp1.split(\",\")\n",
    "        #print(temp1[-1]==\"end \\n\")\n",
    "        if(len(temp1)==24 and temp1[-1]==\"end \\n\"):\n",
    "            csvfile.writelines(temp[1])\n",
    "        \n",
    "    csvfile.close()\n",
    "\n",
    "\n",
    "\n",
    "    df=pd.read_csv(\"myfile.txt\",names=[\"start\",\"q->flow_index\",\"pprms->qdelay_ref\",\"pprms->tupdate\",\"pprms->max_burst\",\"pprms->max_ecnth\",\"pprms->alpha\",\"pprms->beta\",\"pprms->flags\",\"pst->burst_allowance\",\"pst->drop_prob\",\"pst->current_qdelay\",\"pst->qdelay_old\",\"pst->accu_prob\",\"pst->measurement_start\",\"pst->avg_dq_time\",\"pst->dq_count\",\"pst->sflags\",\"q->stats.tot_pkts\",\"q->stats.tot_bytes\",\"q->stats.length\",\"q->stats.len_bytes\",\"q->stats.drops\",\"end\"],header=None)\n",
    "\n",
    "    df=df.drop(columns=['start', 'end'])\n",
    "    df['ecn'] = df['q->flow_index'].map(lambda x: x>2)\n",
    "    df[\"ecn\"] = df[\"ecn\"].astype(int)\n",
    "    df = df.loc[:,df.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "\n",
    "    df['q->flow_index'] = df['q->flow_index'].map(lambda x: x if x<3 else x-3 )\n",
    "    df['q->flow_index'] = df['q->flow_index'].map(lambda x: 0 if x==0 else 1 )\n",
    "\n",
    "    df[\"q->flow_index\"].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import numpy as np\n",
    "    \n",
    "    # copy the data\n",
    "    df_sklearn = df.copy()\n",
    "    \n",
    "    # apply normalization techniques\n",
    "    column = 'pst->burst_allowance'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    column = 'pst->current_qdelay'\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 15))\n",
    "\n",
    "    # Normalize the 'data' column\n",
    "    df_sklearn[column] = scaler.fit_transform(df_sklearn[[column]])\n",
    "\n",
    "    df_sklearn[column] = df_sklearn[column]*-1\n",
    "\n",
    "\n",
    "    column = 'pst->qdelay_old'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "\n",
    "    column = 'pst->accu_prob'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "\n",
    "    column = 'pst->measurement_start'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "    column = 'q->stats.tot_pkts'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "    column = 'q->stats.tot_bytes'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "    column = 'q->stats.length'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "    column = 'q->stats.len_bytes'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "    column = 'q->stats.drops'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # column = 'pst->drop_prob'\n",
    "    # df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "\n",
    "    column1 = 'pst->drop_prob'\n",
    "    column1_max=df_sklearn[column1].abs().max()\n",
    "    column1_min=df_sklearn[column1].abs().min()\n",
    "    # df_sklearn[column1] = df_sklearn[column1] /df_sklearn[column1].abs().max()\n",
    "\n",
    "    df_sklearn[column1] = 2*( df_sklearn[column1]- df_sklearn[column1].abs().min()) /(df_sklearn[column1].abs().max()-df_sklearn[column1].abs().min()) -1\n",
    "\n",
    "\n",
    "    df_sklearn.rename(columns={'pst->burst_allowance': 'burst_allowance', \n",
    "    'pst->drop_prob': 'drop_prob',\n",
    "    'pst->current_qdelay': 'current_qdelay',\n",
    "    'pst->qdelay_old': 'qdelay_old',\n",
    "    'pst->accu_prob': 'accu_prob',\n",
    "    'pst->measurement_start': 'measurement_start',\n",
    "    'q->stats.tot_pkts': 'tot_pkts',\n",
    "    'q->stats.tot_bytes': 'tot_bytes',\n",
    "    'q->stats.length': 'length',\n",
    "    'q->stats.len_bytes': 'len_bytes',\n",
    "    'q->flow_index': 'flow_index',\n",
    "    'q->stats.drops': 'drops'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # view normalized data  \n",
    "    display(df_sklearn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df0 = df_sklearn[df_sklearn['flow_index'] == 0]\n",
    "    df1 = df_sklearn[df_sklearn['flow_index'] == 1]\n",
    "    df0=df0.reset_index(drop=True)\n",
    "    df0=df0.drop(columns=['flow_index'])\n",
    "\n",
    "    \n",
    "    df1=df1.reset_index(drop=True)\n",
    "    df1=df1.drop(columns=['flow_index'])\n",
    "    \n",
    "    if filename==\"router1.txt\":\n",
    "        print(\"1st\")\n",
    "        df0.to_csv(\"data1.csv\")\n",
    "        df1.to_csv(\"data2.csv\")\n",
    "    if filename==\"router2.txt\":\n",
    "        print(\"2nd\")\n",
    "        df0.to_csv(\"data3.csv\")\n",
    "        df1.to_csv(\"data4.csv\")        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kernel_to_csv1(filename=\"router1.txt\"):     \n",
    "        \n",
    "\n",
    "    open('newfile.txt','w').writelines([ line for line in open('router1.txt') if 'fq_calculate_drop_prob-start' in line])\n",
    "    csvfile = open('myfile.txt', 'w')\n",
    "\n",
    "    file1 = open('newfile.txt', 'r')\n",
    "    Lines = file1.readlines()\n",
    "    \n",
    "    count = 0\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        count += 1\n",
    "        temp=line.split(\"-\")\n",
    "        temp1=temp[1]\n",
    "        \n",
    "        temp1=temp1.split(\",\")\n",
    "        #print(temp1[-1]==\"end \\n\")\n",
    "        if(len(temp1)==24 and temp1[-1]==\"end \\n\"):\n",
    "            csvfile.writelines(temp[1])\n",
    "        \n",
    "    csvfile.close()\n",
    "\n",
    "\n",
    "\n",
    "    df=pd.read_csv(\"myfile.txt\",names=[\"start\",\"q->flow_index\",\"pprms->qdelay_ref\",\"pprms->tupdate\",\"pprms->max_burst\",\"pprms->max_ecnth\",\"pprms->alpha\",\"pprms->beta\",\"pprms->flags\",\"pst->burst_allowance\",\"pst->drop_prob\",\"pst->current_qdelay\",\"pst->qdelay_old\",\"pst->accu_prob\",\"pst->measurement_start\",\"pst->avg_dq_time\",\"pst->dq_count\",\"pst->sflags\",\"q->stats.tot_pkts\",\"q->stats.tot_bytes\",\"q->stats.length\",\"q->stats.len_bytes\",\"q->stats.drops\",\"end\"],header=None)\n",
    "\n",
    "    df=df.drop(columns=['start', 'end'])\n",
    "    df['ecn'] = df['q->flow_index'].map(lambda x: x>2)\n",
    "    df[\"ecn\"] = df[\"ecn\"].astype(int)\n",
    "    df = df.loc[:,df.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "\n",
    "    df['q->flow_index'] = df['q->flow_index'].map(lambda x: x if x<3 else x-3 )\n",
    "    df['q->flow_index'] = df['q->flow_index'].map(lambda x: 0 if x==0 else 1 )\n",
    "\n",
    "    df[\"q->flow_index\"].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import numpy as np\n",
    "    \n",
    "    # copy the data\n",
    "    df_sklearn = df.copy()\n",
    "    \n",
    "    # apply normalization techniques\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    column = 'pst->current_qdelay'\n",
    "\n",
    "    \n",
    "    \n",
    "    column1_max=df_sklearn[column].abs().max()\n",
    "    df_sklearn[column] = column1_max- df_sklearn[column]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # column = 'pst->drop_prob'\n",
    "    # df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "\n",
    "    column1 = 'pst->drop_prob'\n",
    "    column1_max=df_sklearn[column1].abs().max()\n",
    "    column1_min=df_sklearn[column1].abs().min()\n",
    "    # df_sklearn[column1] = df_sklearn[column1] /df_sklearn[column1].abs().max()\n",
    "\n",
    "    df_sklearn[column1] = 1000000000*( df_sklearn[column1]- df_sklearn[column1].abs().min()) /(df_sklearn[column1].abs().max()-df_sklearn[column1].abs().min())\n",
    "\n",
    "\n",
    "    df_sklearn.rename(columns={'pst->burst_allowance': 'burst_allowance', \n",
    "    'pst->drop_prob': 'drop_prob',\n",
    "    'pst->current_qdelay': 'current_qdelay',\n",
    "    'pst->qdelay_old': 'qdelay_old',\n",
    "    'pst->accu_prob': 'accu_prob',\n",
    "    'pst->measurement_start': 'measurement_start',\n",
    "    'q->stats.tot_pkts': 'tot_pkts',\n",
    "    'q->stats.tot_bytes': 'tot_bytes',\n",
    "    'q->stats.length': 'length',\n",
    "    'q->stats.len_bytes': 'len_bytes',\n",
    "    'q->flow_index': 'flow_index',\n",
    "    'q->stats.drops': 'drops'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # view normalized data  \n",
    "    display(df_sklearn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df0 = df_sklearn[df_sklearn['flow_index'] == 0]\n",
    "    df1 = df_sklearn[df_sklearn['flow_index'] == 1]\n",
    "    df0=df0.reset_index(drop=True)\n",
    "    df0=df0.drop(columns=['flow_index'])\n",
    "\n",
    "    \n",
    "    df1=df1.reset_index(drop=True)\n",
    "    df1=df1.drop(columns=['flow_index'])\n",
    "    \n",
    "    if filename==\"router1.txt\":\n",
    "        print(\"1st\")\n",
    "        df0.to_csv(\"data_1.csv\")\n",
    "        df1.to_csv(\"data_2.csv\")\n",
    "    if filename==\"router2.txt\":\n",
    "        print(\"2nd\")\n",
    "        df0.to_csv(\"data_3.csv\")\n",
    "        df1.to_csv(\"data_4.csv\")        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kernel_to_csv_2(filename=\"router1.txt\"):     \n",
    "        \n",
    "\n",
    "    open('newfile.txt','w').writelines([ line for line in open('router1.txt') if 'fq_calculate_drop_prob-start' in line])\n",
    "    csvfile = open('myfile.txt', 'w')\n",
    "\n",
    "    file1 = open('newfile.txt', 'r')\n",
    "    Lines = file1.readlines()\n",
    "    \n",
    "    count = 0\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        count += 1\n",
    "        temp=line.split(\"-\")\n",
    "        temp1=temp[1]\n",
    "        \n",
    "        temp1=temp1.split(\",\")\n",
    "        #print(temp1[-1]==\"end \\n\")\n",
    "        if(len(temp1)==24 and temp1[-1]==\"end \\n\"):\n",
    "            csvfile.writelines(temp[1])\n",
    "        \n",
    "    csvfile.close()\n",
    "\n",
    "\n",
    "\n",
    "    df=pd.read_csv(\"myfile.txt\",names=[\"start\",\"q->flow_index\",\"pprms->qdelay_ref\",\"pprms->tupdate\",\"pprms->max_burst\",\"pprms->max_ecnth\",\"pprms->alpha\",\"pprms->beta\",\"pprms->flags\",\"pst->burst_allowance\",\"pst->drop_prob\",\"pst->current_qdelay\",\"pst->qdelay_old\",\"pst->accu_prob\",\"pst->measurement_start\",\"pst->avg_dq_time\",\"pst->dq_count\",\"pst->sflags\",\"q->stats.tot_pkts\",\"q->stats.tot_bytes\",\"q->stats.length\",\"q->stats.len_bytes\",\"q->stats.drops\",\"end\"],header=None)\n",
    "\n",
    "    df=df.drop(columns=['start', 'end'])\n",
    "    df['ecn'] = df['q->flow_index'].map(lambda x: x>2)\n",
    "    df[\"ecn\"] = df[\"ecn\"].astype(int)\n",
    "    df = df.loc[:,df.apply(pd.Series.nunique) != 1]\n",
    "\n",
    "\n",
    "    df['q->flow_index'] = df['q->flow_index'].map(lambda x: x if x<3 else x-3 )\n",
    "    df['q->flow_index'] = df['q->flow_index'].map(lambda x: 0 if x==0 else 1 )\n",
    "\n",
    "    df[\"q->flow_index\"].value_counts()\n",
    "    \n",
    "    print(df['pst->current_qdelay'].max())\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import numpy as np\n",
    "    \n",
    "    # copy the data\n",
    "    df_sklearn = df.copy()\n",
    "    \n",
    "    # apply normalization techniques\n",
    "    column = 'pst->burst_allowance'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Min-Max scaling\n",
    "    column = 'pst->current_qdelay'\n",
    "    min_value = df_sklearn[column].min()\n",
    "    max_value = df_sklearn[column].max()\n",
    "    \n",
    "    import json\n",
    " \n",
    "    # Data to be written\n",
    "    dictionary = {\n",
    "        \"max_value\": max_value,\n",
    "        \"min_value\": min_value\n",
    "    }\n",
    "    \n",
    "    # Serializing json\n",
    "    \n",
    "    # Writing to sample.json\n",
    "    \n",
    "        \n",
    "    with open(\"Min_max_values_for_qdelay.json\", \"w\") as outfile:\n",
    "        json.dump(dictionary, outfile)\n",
    "\n",
    "    df_sklearn[column] = ((df_sklearn[column] - min_value) / (max_value - min_value)) * 15\n",
    "    \n",
    "\n",
    "    # scaler = MinMaxScaler(feature_range=(0, 15))\n",
    "\n",
    "    # # Normalize the 'data' column\n",
    "    # df_sklearn[column] = scaler.fit_transform(df_sklearn[[column]])\n",
    "\n",
    "    df_sklearn[column] = df_sklearn[column]*-1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    column = 'pst->qdelay_old'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "\n",
    "    column = 'pst->accu_prob'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "\n",
    "    column = 'pst->measurement_start'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "    column = 'q->stats.tot_pkts'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "    column = 'q->stats.tot_bytes'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "    column = 'q->stats.length'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "    column = 'q->stats.len_bytes'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "    column = 'q->stats.drops'\n",
    "    df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # column = 'pst->drop_prob'\n",
    "    # df_sklearn[column] = MinMaxScaler().fit_transform(np.array(df_sklearn[column]).reshape(-1,1))\n",
    "\n",
    "\n",
    "    column1 = 'pst->drop_prob'\n",
    "    column1_max=df_sklearn[column1].abs().max()\n",
    "    column1_min=df_sklearn[column1].abs().min()\n",
    "    # df_sklearn[column1] = df_sklearn[column1] /df_sklearn[column1].abs().max()\n",
    "\n",
    "    df_sklearn[column1] = 2*( df_sklearn[column1]- df_sklearn[column1].abs().min()) /(df_sklearn[column1].abs().max()-df_sklearn[column1].abs().min()) -1\n",
    "\n",
    "\n",
    "    df_sklearn.rename(columns={'pst->burst_allowance': 'burst_allowance', \n",
    "    'pst->drop_prob': 'drop_prob',\n",
    "    'pst->current_qdelay': 'current_qdelay',\n",
    "    'pst->qdelay_old': 'qdelay_old',\n",
    "    'pst->accu_prob': 'accu_prob',\n",
    "    'pst->measurement_start': 'measurement_start',\n",
    "    'q->stats.tot_pkts': 'tot_pkts',\n",
    "    'q->stats.tot_bytes': 'tot_bytes',\n",
    "    'q->stats.length': 'length',\n",
    "    'q->stats.len_bytes': 'len_bytes',\n",
    "    'q->flow_index': 'flow_index',\n",
    "    'q->stats.drops': 'drops'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # view normalized data  \n",
    "    display(df_sklearn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df0 = df_sklearn[df_sklearn['flow_index'] == 0]\n",
    "    df1 = df_sklearn[df_sklearn['flow_index'] == 1]\n",
    "    df0=df0.reset_index(drop=True)\n",
    "    df0=df0.drop(columns=['flow_index'])\n",
    "\n",
    "    \n",
    "    df1=df1.reset_index(drop=True)\n",
    "    df1=df1.drop(columns=['flow_index'])\n",
    "    \n",
    "    if filename==\"router1.txt\":\n",
    "        print(\"1st\")\n",
    "        df0.to_csv(\"data1.csv\")\n",
    "        df1.to_csv(\"data2.csv\")\n",
    "    if filename==\"router2.txt\":\n",
    "        print(\"2nd\")\n",
    "        df0.to_csv(\"data3.csv\")\n",
    "        df1.to_csv(\"data4.csv\")        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_index</th>\n",
       "      <th>burst_allowance</th>\n",
       "      <th>drop_prob</th>\n",
       "      <th>current_qdelay</th>\n",
       "      <th>qdelay_old</th>\n",
       "      <th>accu_prob</th>\n",
       "      <th>measurement_start</th>\n",
       "      <th>tot_pkts</th>\n",
       "      <th>tot_bytes</th>\n",
       "      <th>length</th>\n",
       "      <th>len_bytes</th>\n",
       "      <th>drops</th>\n",
       "      <th>ecn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.035831</td>\n",
       "      <td>0.040589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999974</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.026059</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998753</td>\n",
       "      <td>0.332467</td>\n",
       "      <td>0.258881</td>\n",
       "      <td>0.029316</td>\n",
       "      <td>0.022435</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11530</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999974</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.333521</td>\n",
       "      <td>0.260097</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11531</th>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.333914</td>\n",
       "      <td>0.260443</td>\n",
       "      <td>0.074919</td>\n",
       "      <td>0.059728</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11532</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.336365</td>\n",
       "      <td>0.261525</td>\n",
       "      <td>0.035831</td>\n",
       "      <td>0.019040</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11533</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336757</td>\n",
       "      <td>0.261962</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11534 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       flow_index  burst_allowance  drop_prob  current_qdelay  qdelay_old  \\\n",
       "0               1         1.000000  -0.999988         -0.3125    0.020833   \n",
       "1               1         1.000000  -0.999988         -0.3125    0.020833   \n",
       "2               0         1.000000  -0.999988         -0.3125    0.020833   \n",
       "3               1         1.000000  -0.999974         -0.6250    0.041667   \n",
       "4               0         1.000000  -1.000000         -0.0000    0.000000   \n",
       "...           ...              ...        ...             ...         ...   \n",
       "11529           1         0.222222  -1.000000         -0.6250    0.041667   \n",
       "11530           1         1.000000  -0.999974         -0.6250    0.041667   \n",
       "11531           1         0.888889  -0.999963         -0.6250    0.041667   \n",
       "11532           1         1.000000  -0.999988         -0.3125    0.020833   \n",
       "11533           1         1.000000  -0.999988         -0.3125    0.020833   \n",
       "\n",
       "       accu_prob  measurement_start  tot_pkts  tot_bytes    length  len_bytes  \\\n",
       "0            0.0           0.000000  0.000466   0.000590  0.003257   0.003690   \n",
       "1            0.0           0.000873  0.001373   0.001741  0.035831   0.040589   \n",
       "2            0.0           0.001496  0.000392   0.000287  0.003257   0.003690   \n",
       "3            0.0           0.001621  0.001863   0.002363  0.026059   0.029519   \n",
       "4            0.0           0.001621  0.000637   0.000568  0.000000   0.000000   \n",
       "...          ...                ...       ...        ...       ...        ...   \n",
       "11529        0.0           0.998753  0.332467   0.258881  0.029316   0.022435   \n",
       "11530        0.0           0.999377  0.333521   0.260097  0.022801   0.018646   \n",
       "11531        0.0           0.999377  0.333914   0.260443  0.074919   0.059728   \n",
       "11532        0.0           0.999875  0.336365   0.261525  0.035831   0.019040   \n",
       "11533        0.0           1.000000  0.336757   0.261962  0.022801   0.018646   \n",
       "\n",
       "          drops  ecn  \n",
       "0      0.000000    1  \n",
       "1      0.000000    1  \n",
       "2      0.000000    0  \n",
       "3      0.000000    1  \n",
       "4      0.000000    0  \n",
       "...         ...  ...  \n",
       "11529  0.126106    0  \n",
       "11530  0.126106    0  \n",
       "11531  0.126106    0  \n",
       "11532  0.126106    0  \n",
       "11533  0.126106    0  \n",
       "\n",
       "[11534 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st\n",
      "480000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_index</th>\n",
       "      <th>burst_allowance</th>\n",
       "      <th>drop_prob</th>\n",
       "      <th>current_qdelay</th>\n",
       "      <th>qdelay_old</th>\n",
       "      <th>accu_prob</th>\n",
       "      <th>measurement_start</th>\n",
       "      <th>tot_pkts</th>\n",
       "      <th>tot_bytes</th>\n",
       "      <th>length</th>\n",
       "      <th>len_bytes</th>\n",
       "      <th>drops</th>\n",
       "      <th>ecn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.035831</td>\n",
       "      <td>0.040589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999974</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.026059</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998753</td>\n",
       "      <td>0.332467</td>\n",
       "      <td>0.258881</td>\n",
       "      <td>0.029316</td>\n",
       "      <td>0.022435</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11530</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999974</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.333521</td>\n",
       "      <td>0.260097</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11531</th>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.6250</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.333914</td>\n",
       "      <td>0.260443</td>\n",
       "      <td>0.074919</td>\n",
       "      <td>0.059728</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11532</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.336365</td>\n",
       "      <td>0.261525</td>\n",
       "      <td>0.035831</td>\n",
       "      <td>0.019040</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11533</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999988</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336757</td>\n",
       "      <td>0.261962</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.126106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11534 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       flow_index  burst_allowance  drop_prob  current_qdelay  qdelay_old  \\\n",
       "0               1         1.000000  -0.999988         -0.3125    0.020833   \n",
       "1               1         1.000000  -0.999988         -0.3125    0.020833   \n",
       "2               0         1.000000  -0.999988         -0.3125    0.020833   \n",
       "3               1         1.000000  -0.999974         -0.6250    0.041667   \n",
       "4               0         1.000000  -1.000000         -0.0000    0.000000   \n",
       "...           ...              ...        ...             ...         ...   \n",
       "11529           1         0.222222  -1.000000         -0.6250    0.041667   \n",
       "11530           1         1.000000  -0.999974         -0.6250    0.041667   \n",
       "11531           1         0.888889  -0.999963         -0.6250    0.041667   \n",
       "11532           1         1.000000  -0.999988         -0.3125    0.020833   \n",
       "11533           1         1.000000  -0.999988         -0.3125    0.020833   \n",
       "\n",
       "       accu_prob  measurement_start  tot_pkts  tot_bytes    length  len_bytes  \\\n",
       "0            0.0           0.000000  0.000466   0.000590  0.003257   0.003690   \n",
       "1            0.0           0.000873  0.001373   0.001741  0.035831   0.040589   \n",
       "2            0.0           0.001496  0.000392   0.000287  0.003257   0.003690   \n",
       "3            0.0           0.001621  0.001863   0.002363  0.026059   0.029519   \n",
       "4            0.0           0.001621  0.000637   0.000568  0.000000   0.000000   \n",
       "...          ...                ...       ...        ...       ...        ...   \n",
       "11529        0.0           0.998753  0.332467   0.258881  0.029316   0.022435   \n",
       "11530        0.0           0.999377  0.333521   0.260097  0.022801   0.018646   \n",
       "11531        0.0           0.999377  0.333914   0.260443  0.074919   0.059728   \n",
       "11532        0.0           0.999875  0.336365   0.261525  0.035831   0.019040   \n",
       "11533        0.0           1.000000  0.336757   0.261962  0.022801   0.018646   \n",
       "\n",
       "          drops  ecn  \n",
       "0      0.000000    1  \n",
       "1      0.000000    1  \n",
       "2      0.000000    0  \n",
       "3      0.000000    1  \n",
       "4      0.000000    0  \n",
       "...         ...  ...  \n",
       "11529  0.126106    0  \n",
       "11530  0.126106    0  \n",
       "11531  0.126106    0  \n",
       "11532  0.126106    0  \n",
       "11533  0.126106    0  \n",
       "\n",
       "[11534 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd\n"
     ]
    }
   ],
   "source": [
    "convert_kernel_to_csv_2(\"router1.txt\")\n",
    "convert_kernel_to_csv_2(\"router2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_kernel_to_csv1(\"router1.txt\")\n",
    "# convert_kernel_to_csv1(\"router2.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
